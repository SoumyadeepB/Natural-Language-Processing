{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Speaker Encoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import librosa as lr\n",
    "import librosa.display as ld\n",
    "import glob\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nnabla as nn\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.functions as F\n",
    "import nnabla.solvers as S\n",
    "import tensorflow as tf\n",
    "from nnabla.utils.data_iterator import data_iterator_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Hyperparameters (to be moved to hparams.py)  #######################\n",
    "\n",
    "### Directory Locations ###\n",
    "#basedir = 'drive/My Drive/Colab Notebooks/SV2TTS'\n",
    "data_dir = \"./data/LJSpeech/\"\n",
    "label_dir = \"./data/LJSpeech/labels/\"\n",
    "save_dir_mfcc = \"./data/LJSpeech/mfcc/\"\n",
    "save_dir_transcripts = \"./data/LJSpeech/transcripts/\"\n",
    "\n",
    "### FFT Parameters ###\n",
    "sr = 22500\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mfcc = 13\n",
    "mel_len = 290                      # frame length of mel spectrogram > Spectrogram is split into short-time frames\n",
    "n_fft = 1024 \n",
    "n_mels = 80                        # number of mel filters (number of Mel bands to generate)\n",
    "hop_length = 256                   # audio samples between adjacent STFT columns\n",
    "win_length = 1024                  # window length\n",
    "mel_fmin = 0.0                     # minimum mel bank\n",
    "mel_fmax = 8000                    # maximum mel bank\n",
    "r = 3                              # number of frames generated on each timestep\n",
    "\n",
    "### Model Parameters ###\n",
    "batch_size = 128\n",
    "lstm_layers = 3\n",
    "lstm_hidden = 256\n",
    "lstm_directions = 1\n",
    "affine_hidden = 256\n",
    "embed_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.load(label_dir + 's_id.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.utils.to_categorical(ys, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9725/9725 [00:02<00:00, 3654.27it/s]\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "mfccs = sorted(glob.glob(save_dir_mfcc + '*.npy'))\n",
    "for i in tqdm(range(len(mfccs))):\n",
    "    xs.append(np.load(mfccs[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_network(inputs, training):\n",
    "    with nn.parameter_scope('encoder_network/lstm'):\n",
    "        h = nn.Variable((lstm_layers, lstm_directions, batch_size, lstm_hidden))\n",
    "        c = nn.Variable((lstm_layers, lstm_directions, batch_size, lstm_hidden))\n",
    "        y, hn, cn = PF.lstm((inputs, h, c), training = training)\n",
    "    with nn.parameter_scope('encoder_network/dense'):\n",
    "        out = PF.affine(hn[-1], affine_hidden)\n",
    "        out = F.relu(out) \n",
    "        embeds = out/(np.linalg.norm(out,'fro'))\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LJ001': 0, 'LJ002': 1, 'LJ003': 2, 'LJ004': 3, 'LJ005': 4, 'LJ006': 5, 'LJ007': 6, 'LJ008': 7, 'LJ009': 8, 'LJ010': 9}\n"
     ]
    }
   ],
   "source": [
    "idx = {k: i for i, k in enumerate(sorted(set(ys)))}\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(ys):\n",
    "    idx = {k: i for i, k in enumerate(sorted(set(ys)))}\n",
    "    labels = [idx[i] for i in ys]\n",
    "    labels = np.array(labels)\n",
    "    nb_classes = len(set(labels))\n",
    "    res = np.eye(nb_classes)[np.array(labels).reshape(-1)]\n",
    "    return res.reshape(list(labels.shape)+[nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = get_one_hot(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_func(i):\n",
    "    return(xs[i], ys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 17:18:40,365 [nnabla][INFO]: DataSource with shuffle(True)\n",
      "2020-12-06 17:18:40,367 [nnabla][INFO]: Using DataSourceWithMemoryCache\n",
      "2020-12-06 17:18:40,368 [nnabla][INFO]: DataSource with shuffle(True)\n",
      "2020-12-06 17:18:40,369 [nnabla][INFO]: On-memory\n",
      "2020-12-06 17:18:40,369 [nnabla][INFO]: Using DataIterator\n"
     ]
    }
   ],
   "source": [
    "inputs = nn.utils.data_iterator.data_iterator_simple(load_func, \n",
    "                                                     len(ys), \n",
    "                                                     batch_size, \n",
    "                                                     shuffle = True, \n",
    "                                                     with_file_cache = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9725, 13, 141)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Get total utterances for each speaker\n",
    "'''\n",
    "\n",
    "utter_count = {k: 0 for k in sorted(set(ys))}\n",
    "mfccs = {k:[] for k in sorted(set(ys))}\n",
    "\n",
    "for i, s_id in enumerate(ys):\n",
    "    utter_count[s_id]+=1\n",
    "    mfccs[s_id].append(xs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LJ001': 598, 'LJ002': 1130, 'LJ003': 1201, 'LJ004': 816, 'LJ005': 989, 'LJ006': 1049, 'LJ007': 850, 'LJ008': 1031, 'LJ009': 973, 'LJ010': 1088}\n",
      "(598, 13, 141)\n",
      "(1130, 13, 141)\n",
      "(1201, 13, 141)\n",
      "(816, 13, 141)\n",
      "(989, 13, 141)\n",
      "(1049, 13, 141)\n",
      "(850, 13, 141)\n",
      "(1031, 13, 141)\n",
      "(973, 13, 141)\n",
      "(1088, 13, 141)\n"
     ]
    }
   ],
   "source": [
    "print(utter_count)\n",
    "for key in mfccs:\n",
    "    print(np.array(mfccs[key]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.021952  , -2.997819  , -3.0747917 , ..., -2.6599905 ,\n",
       "        -2.8426325 , -2.770187  ],\n",
       "       [-0.86400616, -0.7827282 , -0.6735879 , ...,  0.94493216,\n",
       "         1.0947886 ,  1.4090455 ],\n",
       "       [ 0.9714152 ,  1.0112687 ,  0.8982654 , ...,  0.5989028 ,\n",
       "         0.6586964 ,  0.80930406],\n",
       "       ...,\n",
       "       [ 0.01241515, -0.00476354, -0.0360523 , ...,  0.06325874,\n",
       "         0.10073408,  0.1603219 ],\n",
       "       [ 0.5045489 ,  0.48247862,  0.43978587, ...,  0.17858744,\n",
       "         0.16974679,  0.1903773 ],\n",
       "       [ 0.12723784,  0.18586203,  0.19485734, ...,  0.04302476,\n",
       "         0.07867512,  0.12346806]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs['LJ001'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create customized dataset\n",
    "'''\n",
    "n_speakers = len(set(utter_count)) #number of speakers\n",
    "n_utterances = 2 #utterances per batch\n",
    "max_utter = utter_count[max(utter_count, key=utter_count.get)] \n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "## Batch_size =20 , each batch will contain 2 utterances from each of the 10 speakers\n",
    "def split_dataset(xs, ys):\n",
    "    \n",
    "    for i in tqdm(range(max_utter)):\n",
    "        \n",
    "        for s_id in utter_count:\n",
    "            max_idx = utter_count[s_id] #Allow repeating data\n",
    "            \n",
    "            ## Appending n_utterances for each speaker (in one batch)\n",
    "            for j in range(n_utterances):\n",
    "                data = mfccs[s_id][(i+j)%max_idx]\n",
    "                dataset.append(data)\n",
    "                labels.append(s_id)\n",
    "                \n",
    "                \n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1201/1201 [00:00<00:00, 104353.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, labels = split_dataset(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_batch(batch_size):\n",
    "    batch_data = dataset[:batch_size]\n",
    "    batch_labels = labels[:batch_size]\n",
    "    del dataset[:batch_size]\n",
    "    del labels[:batch_size]\n",
    "    dataset += batch_data\n",
    "    labels += batch_labels\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = len(dataset)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(embeddings):\n",
    "    \"\"\"\n",
    "        Computes the similarity matrix according the section 2.1 of GE2E.\n",
    "        :param embeds: the embeddings as a tensor of shape (speakers_per_batch, \n",
    "        utterances_per_speaker, embedding_size)\n",
    "        :return: the similarity matrix as a tensor of shape (speakers_per_batch,\n",
    "        utterances_per_speaker, speakers_per_batch)\n",
    "        \"\"\"\n",
    "    embeddings = np.reshape(embeddings, [n_speakers, n_utterances, embed_size])\n",
    "    centroids_incl = embeddings.mean(axis = 1, keepdims = True) # one centroid per speaker\n",
    "    centroids_incl = centroids_incl/np.linalg.norm(centroids_incl, axis = 2, keepdims = True)\n",
    "    \n",
    "    centroids_excl = np.sum(embeddings, axis = 1, keepdims = True) - embeddings\n",
    "    centroids_excl /= (n_utterances - 1)\n",
    "    centroids_excl = centroids_excl/np.linalg.norm(centroids_excl, axis = 2, keepdims = True)\n",
    "    \n",
    "    sim_matrix = np.zeros(n_speakers, n_utterances, n_speakers)\n",
    "    mask_matrix = 1 - np.eye(n_speakers, dtype = np.int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-7e54ba96613d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_speakers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_utterances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[[ 1.,  2.],\n",
    "    [ 3.,  4.],\n",
    "    [ 0.,  3.]],\n",
    "   [[ 1.,  2.],\n",
    "    [ 2.,  1.],\n",
    "    [ 1.,  2.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.],\n",
       "        [3., 4.],\n",
       "        [0., 3.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [2., 1.],\n",
       "        [1., 2.]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4., 9.]],\n",
       "\n",
       "       [[4., 5.]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.sum(arr, axis=1, keepdims=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3., 7.],\n",
       "        [1., 5.],\n",
       "        [4., 6.]],\n",
       "\n",
       "       [[3., 3.],\n",
       "        [2., 4.],\n",
       "        [3., 3.]]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d - arr\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit54af622977484619b47ea42e3ff533e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
