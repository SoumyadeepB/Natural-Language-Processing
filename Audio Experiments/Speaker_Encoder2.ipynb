{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Speaker Encoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import librosa as lr\n",
    "import librosa.display as ld\n",
    "import glob\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nnabla as nn\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.functions as F\n",
    "import nnabla.solvers as S\n",
    "import tensorflow as tf\n",
    "from nnabla.utils.data_iterator import data_iterator_simple\n",
    "import nnabla.monitor as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Hyperparameters (to be moved to hparams.py)  #######################\n",
    "\n",
    "### Directory Locations ###\n",
    "#basedir = 'drive/My Drive/Colab Notebooks/SV2TTS'\n",
    "data_dir = \"./data/LJSpeech/\"\n",
    "label_dir = \"./data/LJSpeech/labels/\"\n",
    "save_dir_mfcc = \"./data/LJSpeech/mfcc/\"\n",
    "save_dir_transcripts = \"./data/LJSpeech/transcripts/\"\n",
    "\n",
    "### FFT Parameters ###\n",
    "sr = 22500\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mfcc = 13\n",
    "mel_len = 290                      # frame length of mel spectrogram > Spectrogram is split into short-time frames\n",
    "n_fft = 1024 \n",
    "n_mels = 80                        # number of mel filters (number of Mel bands to generate)\n",
    "hop_length = 256                   # audio samples between adjacent STFT columns\n",
    "win_length = 1024                  # window length\n",
    "mel_fmin = 0.0                     # minimum mel bank\n",
    "mel_fmax = 8000                    # maximum mel bank\n",
    "r = 3                              # number of frames generated on each timestep\n",
    "\n",
    "### Model Parameters ###\n",
    "batch_size = 20\n",
    "lstm_layers = 3\n",
    "lstm_hidden = 256\n",
    "lstm_directions = 1\n",
    "affine_hidden = 256\n",
    "embed_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.load(label_dir + 's_id.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.utils.to_categorical(ys, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9725/9725 [00:02<00:00, 3654.27it/s]\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "mfccs = sorted(glob.glob(save_dir_mfcc + '*.npy'))\n",
    "for i in tqdm(range(len(mfccs))):\n",
    "    xs.append(np.load(mfccs[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_network(inputs, training = False):\n",
    "    with nn.parameter_scope('encoder_network/lstm'):\n",
    "        h = nn.Variable((lstm_layers, lstm_directions, batch_size, lstm_hidden))\n",
    "        c = nn.Variable((lstm_layers, lstm_directions, batch_size, lstm_hidden))\n",
    "        print(\"Encoder:\")\n",
    "        print(h.shape)\n",
    "        \n",
    "        y, hn, cn = PF.lstm(inputs, h, c, training = training)\n",
    "    with nn.parameter_scope('encoder_network/dense'):\n",
    "        out = PF.affine(hn[-1], affine_hidden)\n",
    "        out = F.relu(out) \n",
    "        embeds = out/(np.linalg.norm(out,'fro'))\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LJ001': 0, 'LJ002': 1, 'LJ003': 2, 'LJ004': 3, 'LJ005': 4, 'LJ006': 5, 'LJ007': 6, 'LJ008': 7, 'LJ009': 8, 'LJ010': 9}\n"
     ]
    }
   ],
   "source": [
    "idx = {k: i for i, k in enumerate(sorted(set(ys)))}\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(ys):\n",
    "    idx = {k: i for i, k in enumerate(sorted(set(ys)))}\n",
    "    labels = [idx[i] for i in ys]\n",
    "    labels = np.array(labels)\n",
    "    nb_classes = len(set(labels))\n",
    "    res = np.eye(nb_classes)[np.array(labels).reshape(-1)]\n",
    "    return res.reshape(list(labels.shape)+[nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = get_one_hot(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_func(i):\n",
    "    return(xs[i], ys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 17:18:40,365 [nnabla][INFO]: DataSource with shuffle(True)\n",
      "2020-12-06 17:18:40,367 [nnabla][INFO]: Using DataSourceWithMemoryCache\n",
      "2020-12-06 17:18:40,368 [nnabla][INFO]: DataSource with shuffle(True)\n",
      "2020-12-06 17:18:40,369 [nnabla][INFO]: On-memory\n",
      "2020-12-06 17:18:40,369 [nnabla][INFO]: Using DataIterator\n"
     ]
    }
   ],
   "source": [
    "inputs = nn.utils.data_iterator.data_iterator_simple(load_func, \n",
    "                                                     len(ys), \n",
    "                                                     batch_size, \n",
    "                                                     shuffle = True, \n",
    "                                                     with_file_cache = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9725, 13, 141)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Get total utterances for each speaker\n",
    "'''\n",
    "\n",
    "utter_count = {k: 0 for k in sorted(set(ys))}\n",
    "mfccs = {k:[] for k in sorted(set(ys))}\n",
    "\n",
    "for i, s_id in enumerate(ys):\n",
    "    utter_count[s_id]+=1\n",
    "    mfccs[s_id].append(xs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LJ001': 598, 'LJ002': 1130, 'LJ003': 1201, 'LJ004': 816, 'LJ005': 989, 'LJ006': 1049, 'LJ007': 850, 'LJ008': 1031, 'LJ009': 973, 'LJ010': 1088}\n",
      "(598, 13, 141)\n",
      "(1130, 13, 141)\n",
      "(1201, 13, 141)\n",
      "(816, 13, 141)\n",
      "(989, 13, 141)\n",
      "(1049, 13, 141)\n",
      "(850, 13, 141)\n",
      "(1031, 13, 141)\n",
      "(973, 13, 141)\n",
      "(1088, 13, 141)\n"
     ]
    }
   ],
   "source": [
    "print(utter_count)\n",
    "for key in mfccs:\n",
    "    print(np.array(mfccs[key]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.021952  , -2.997819  , -3.0747917 , ..., -2.6599905 ,\n",
       "        -2.8426325 , -2.770187  ],\n",
       "       [-0.86400616, -0.7827282 , -0.6735879 , ...,  0.94493216,\n",
       "         1.0947886 ,  1.4090455 ],\n",
       "       [ 0.9714152 ,  1.0112687 ,  0.8982654 , ...,  0.5989028 ,\n",
       "         0.6586964 ,  0.80930406],\n",
       "       ...,\n",
       "       [ 0.01241515, -0.00476354, -0.0360523 , ...,  0.06325874,\n",
       "         0.10073408,  0.1603219 ],\n",
       "       [ 0.5045489 ,  0.48247862,  0.43978587, ...,  0.17858744,\n",
       "         0.16974679,  0.1903773 ],\n",
       "       [ 0.12723784,  0.18586203,  0.19485734, ...,  0.04302476,\n",
       "         0.07867512,  0.12346806]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs['LJ001'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create customized dataset\n",
    "'''\n",
    "n_speakers = len(set(utter_count)) #number of speakers\n",
    "n_utterances = 2 #utterances per batch\n",
    "max_utter = utter_count[max(utter_count, key=utter_count.get)] \n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "## Batch_size =20 , each batch will contain 2 utterances from each of the 10 speakers\n",
    "def split_dataset(xs, ys):\n",
    "    \n",
    "    for i in tqdm(range(max_utter)):\n",
    "        \n",
    "        for s_id in utter_count:\n",
    "            max_idx = utter_count[s_id] #Allow repeating data\n",
    "            \n",
    "            ## Appending n_utterances for each speaker (in one batch)\n",
    "            for j in range(n_utterances):\n",
    "                data = mfccs[s_id][(i+j)%max_idx]\n",
    "                dataset.append(data)\n",
    "                labels.append(s_id)\n",
    "                \n",
    "                \n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1201/1201 [00:00<00:00, 133794.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, labels = split_dataset(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(dataset,labels, batch_size):\n",
    "    batch_data = dataset[:batch_size]\n",
    "    batch_labels = labels[:batch_size]\n",
    "    del dataset[:batch_size]\n",
    "    del labels[:batch_size]\n",
    "    dataset += batch_data\n",
    "    labels += batch_labels\n",
    "    \n",
    "    return np.array(batch_data), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weight = nn.Variable([1], need_grad = True)\n",
    "sim_weight.d = 10.0\n",
    "sim_bias = nn.Variable([1], need_grad = True)\n",
    "sim_bias.d = -5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(embeddings):\n",
    "    \"\"\"\n",
    "        Computes the similarity matrix according the section 2.1 of GE2E.\n",
    "        :param embeds: the embeddings as a tensor of shape (speakers_per_batch, \n",
    "        utterances_per_speaker, embedding_size)\n",
    "        :return: the similarity matrix as a tensor of shape (speakers_per_batch,\n",
    "        utterances_per_speaker, speakers_per_batch)\n",
    "        \"\"\"\n",
    "    embeddings = np.reshape(embeddings, [n_speakers, n_utterances, embed_size])\n",
    "    centroids_incl = embeddings.mean(axis = 1, keepdims = True) # one centroid per speaker\n",
    "    centroids_incl = centroids_incl/np.linalg.norm(centroids_incl, axis = 2, keepdims = True)\n",
    "    \n",
    "    centroids_excl = np.sum(embeddings, axis = 1, keepdims = True) - embeddings\n",
    "    centroids_excl /= (n_utterances - 1)\n",
    "    centroids_excl = centroids_excl/np.linalg.norm(centroids_excl, axis = 2, keepdims = True)\n",
    "    \n",
    "    sim_matrix = np.zeros(n_speakers, n_utterances, n_speakers)\n",
    "    mask_matrix = 1 - np.eye(n_speakers, dtype = np.int)\n",
    "    \n",
    "    for j in range(n_speakers):\n",
    "        mask = np.where(mask_matrix[j])[0]\n",
    "        sim_matrix[mask, :, j] = (embeddings[mask] * centroids_incl[j]).sum(axis=2)\n",
    "        sim_matrix[j, :, j] = (embeddings[j] * centroids_excl[j]).sum(axis=1)\n",
    "        \n",
    "    sim_matrix = sim_matrix * sim_weight + sim_bias\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(embeddings):\n",
    "    sim_matrix = similarity_matrix(embeddings)\n",
    "    sim_matrix = sim_matrix.reshape((n_speakers * n_utterances, n_speakers))\n",
    "    ground_truth = np.repeat(np.arange(n_speakers), n_utterances)\n",
    "    loss = F.softmax_cross_entropy(sim_matrix, get_one_hot(ground_truth, n_speakers))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(xs):\n",
    "    embeds = encoder_network(xs, training = True)\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = len(dataset)//batch_size\n",
    "max_epochs = 1000\n",
    "\n",
    "def train():\n",
    "    monitor = M.Monitor('.')\n",
    "    monitor_loss = M.MonitorSeries(\n",
    "        \"Training loss\", monitor, interval=1000)\n",
    "    monitor_time = M.MonitorTimeElapsed(\n",
    "        \"Training time\", monitor, interval=1000)\n",
    "    optimizer = S.RMSprop()\n",
    "        \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        #Iterations per epoch\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            xi = nn.Variable((batch_size, 13,141))            \n",
    "            xi.d, yi = generate_batch(dataset,labels, batch_size)\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = encoder_network(xi, True)\n",
    "            loss = get_loss(embeddings)\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "        \n",
    "            # monitor\n",
    "            itr = epoch * n_batch + i\n",
    "            monitor_loss.add(itr, loss.d)\n",
    "            monitor_time.add(itr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder:\n",
      "(3, 1, 20, 256)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "value error in nbla::LSTM<float>::setup_impl\nc:\\ci\\builds\\5czz_5xk\\0\\nnabla\\builders\\all\\nnabla\\src\\nbla\\function\\./generic/lstm.cpp:48\nFailed `hshape[2] == batch_size_`: Input h must be a 4 dimensional array with a shape of (num_layers, num_directions, batch_size, hidden_size).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-250-05a315369e7b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-256-31d74674ae89>\u001b[0m in \u001b[0;36mencoder_network\u001b[1;34m(inputs, training)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameter_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder_network/dense'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mlstm\u001b[1;34m(x, h, c, w0_init, w_init, b_init, num_layers, dropout, bidirectional, training, rng, with_bias, fix_parameters, name)\u001b[0m\n",
      "\u001b[1;32mD:\\Installations\\Python\\lib\\site-packages\\nnabla\\parametric_functions.py\u001b[0m in \u001b[0;36mlstm\u001b[1;34m(x, h, c, w0_init, w_init, b_init, num_layers, dropout, bidirectional, training, rng, with_bias, fix_parameters)\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unlinked_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneed_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mfix_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_l0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<lstm>\u001b[0m in \u001b[0;36mlstm\u001b[1;34m(x, h, c, weight_l0, weight, bias, num_layers, dropout, bidirectional, training, n_outputs, outputs)\u001b[0m\n",
      "\u001b[1;32mD:\\Installations\\Python\\lib\\site-packages\\nnabla\\function_bases.py\u001b[0m in \u001b[0;36mlstm\u001b[1;34m(ctx, x, h, c, weight_l0, weight, bias, num_layers, dropout, bidirectional, training, n_outputs, outputs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_forward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_auto_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mfunction.pyx\u001b[0m in \u001b[0;36mnnabla.function.Function.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfunction.pyx\u001b[0m in \u001b[0;36mnnabla.function.Function._cg_call\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: value error in nbla::LSTM<float>::setup_impl\nc:\\ci\\builds\\5czz_5xk\\0\\nnabla\\builders\\all\\nnabla\\src\\nbla\\function\\./generic/lstm.cpp:48\nFailed `hshape[2] == batch_size_`: Input h must be a 4 dimensional array with a shape of (num_layers, num_directions, batch_size, hidden_size).\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit54af622977484619b47ea42e3ff533e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
